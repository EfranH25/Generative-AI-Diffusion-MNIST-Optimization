{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook used to get FID scores for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('C'), WindowsPath('/Users/Efran/anaconda3/envs/compsci682/lib')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 8.9.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n",
      "cant import bitsandbytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: C:\\Users\\Efran\\anaconda3\\envs\\compsci682 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#? resources\n",
    "#? vid 1: https://www.youtube.com/watch?v=HoKDTa5jHvg&t=177s\n",
    "# explains how ddpm works\n",
    "#? vid2: https://www.youtube.com/watch?v=TBCRlnwJtZU\n",
    "# goes over implementation to ddpm\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from helper_utils import *\n",
    "\n",
    "from modules import UNet, UNet_conditional, EMA\n",
    "import logging \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# library for quantization\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "    print('imported bitsandbytes')\n",
    "    \n",
    "except:\n",
    "    print('cant import bitsandbytes')\n",
    "    bnb = None\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\", USE_GPU = True):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size #resoultion of image #: side note from video --> for higher resolutions, training seperate upsamplers instead of training on bigger resolution images\n",
    "        self.device = device\n",
    "        \n",
    "        if USE_GPU and torch.cuda.is_available():\n",
    "            print(\"CUDAAAAAAAAAAA\")\n",
    "            self.use_cuda = torch.device('cuda')\n",
    "        else:\n",
    "            self.use_cuda = torch.device('cpu')\n",
    "        \n",
    "        #? right now using simple beta schedule --> open AI using cosine scheduler        \n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "        \n",
    "        #! try implementing cosine scheduler\n",
    "        \n",
    "    def prepare_noise_schedule(self):\n",
    "        #? Creates a one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "    \n",
    "    def noise_images(self, x, t):\n",
    "        \"\"\"Adds noise to image. You can iteratively add noise to image but vid 1 showed \n",
    "        a simplification that adds noise in 1 step. Which is this implementation\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "            t (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: returns image with noise added on\n",
    "        \"\"\"\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        E = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * E, E\n",
    "    \n",
    "    def sample_timesteps(self, n):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        #? needed for algorithm for training\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "    \n",
    "\n",
    "    def sample(self, model, n, labels, channels=3, cfg_scale=3):\n",
    "        \"\"\"implements algorithm 2 from the ddpm paper in vid 1\n",
    "\n",
    "        Args:\n",
    "            model (_type_): _description_\n",
    "            n (int): number of images we want to sample \n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        #? see here for why we set model.eval() https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n",
    "        #? essentially disables some some parts of torch for specific steps\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            #? create initial images by sampling over normal dist (step 1)\n",
    "            x = torch.randn((n, channels, self.img_size, self.img_size)).to(self.device)\n",
    "            \n",
    "            #? step 2, 3, 4\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device) #? tensor of timestep\n",
    "                predicted_noise = model(x, t, labels) #? feed that into model w/ current images\n",
    "                \n",
    "                #? noise\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = model(x, t, None)\n",
    "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                \n",
    "                #? only want noise for timestemps greater than 1. done so b/c in last iteration, would make final outcome worse due to adding noise to finalized pixels\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                    \n",
    "                #? alter image by removed a little bit of noise\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        \n",
    "        #? switch back to train    \n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2 #? brings back value to 0-1 range \n",
    "        x = (x * 255).type(torch.uint8) #? bring back values to pixel range for viewing image\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FID Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mnist dataset\n",
      "torch.Size([60000, 28, 28])\n",
      "loaded mnist training dataset\n",
      "Size of his data set:  60000\n"
     ]
    }
   ],
   "source": [
    "#? load mnist data set\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "args.batch_size = 16\n",
    "args.dataset_path = r\"mnist\"\n",
    "args.image_size = 56\n",
    "args.channels = 1\n",
    "dataloader = get_data(args)\n",
    "\n",
    "def get_fid_score(path, mnist, model_names = ('49_ckpt.pt', '49_ema_ckpt.pt')):\n",
    "    mnist_dataset = mnist.dataset\n",
    "    \n",
    "    \n",
    "    #? load models\n",
    "    model_path = path\n",
    "    loaded_unet_model = torch.load(os.path.join(model_path, model_names[0]))\n",
    "    loaded_unet_model.eval()\n",
    "\n",
    "    loaded_ema_model = torch.load(os.path.join(model_path, model_names[1]))\n",
    "    loaded_ema_model.eval()\n",
    "\n",
    "    diffusion = Diffusion(img_size=args.image_size, device='cuda')\n",
    "    print('loaded models')\n",
    "\n",
    "    #? load FID\n",
    "    from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "    fid = FrechetInceptionDistance(normalize=True)\n",
    "    fid_batch_size = 16\n",
    "    \n",
    "    \n",
    "    num_list = [random.randint(0, 9) for x in range(fid_batch_size)]\n",
    "    labels = torch.tensor(num_list).long().to('cuda')\n",
    "    print(labels, len(labels))\n",
    "\n",
    "    #? create sample images for conditional\n",
    "    sampled_images = diffusion.sample(loaded_unet_model, n=len(labels), channels=1, labels=labels)\n",
    "    \n",
    "    real_images = torch.stack([mnist_dataset[i][0] for i in range(fid_batch_size)],0)\n",
    "    print(real_images.shape)\n",
    "\n",
    "    fake_images = torch.stack([sampled_images, sampled_images, sampled_images], dim=1).reshape(fid_batch_size,3,56,56)\n",
    "    real_images = torch.stack([real_images, real_images, real_images], dim=1).reshape(fid_batch_size,3,56,56)\n",
    "    \n",
    "    fake_images = fake_images.to(\"cpu\")\n",
    "    fid.update(real_images, real=True)\n",
    "    fid.update(fake_images, real=False)\n",
    "    conditional_fid = fid.compute()\n",
    "\n",
    "    print('conditional fid:', conditional_fid)\n",
    "    \n",
    "    ema_sampled_images = diffusion.sample(loaded_ema_model, n=len(labels), channels=1, labels=labels)\n",
    "    fid = FrechetInceptionDistance(normalize=True)\n",
    "    fake_images = torch.stack([ema_sampled_images, ema_sampled_images, ema_sampled_images], dim=1).reshape(fid_batch_size,3,56,56)\n",
    "\n",
    "    fake_images = fake_images.to(\"cpu\")\n",
    "    fid.update(real_images, real=True)\n",
    "    fid.update(fake_images, real=False)\n",
    "    fid.compute()\n",
    "\n",
    "    conditional__ema_fid = fid.compute()\n",
    "\n",
    "    print('conditional ema fid:', conditional__ema_fid)\n",
    "    \n",
    "    return conditional_fid, conditional__ema_fid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### base model + deepwise model fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mnist dataset\n",
      "torch.Size([60000, 28, 28])\n",
      "loaded mnist training dataset\n",
      "Size of his data set:  60000\n",
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:33 - INFO: Sampling 16 new images....\n",
      "12:33:33 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 0, 4, 2, 4, 9, 1, 3, 6, 3, 8, 7, 3, 4, 9, 0], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:21, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:58 - INFO: Sampling 16 new images....\n",
      "12:34:58 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(284.2845)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:19, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(267.2341)\n",
      "(tensor(284.2845), tensor(267.2341))\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_data(args)\n",
    "model_path = r'F:\\Classes\\COMPSCI 682\\denoising-diffusion-pytorch-main\\ddpm\\models\\base_mnist_ddpm_conditional_ema'\n",
    "\n",
    "results = get_fid_score(model_path, dataloader)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:08:32 - INFO: Sampling 16 new images....\n",
      "05:08:32 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 9, 1, 4, 9, 6, 6, 3, 7, 2, 5, 3, 2, 3, 9, 8], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:22, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:09:59 - INFO: Sampling 16 new images....\n",
      "05:09:59 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(308.4738)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:26, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(303.7385)\n",
      "(tensor(308.4738), tensor(303.7385))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'F:\\Classes\\COMPSCI 682\\denoising-diffusion-pytorch-main\\ddpm\\models\\d_2_mnist_ddpm_conditional_ema'\n",
    "\n",
    "results = get_fid_score(model_path, dataloader)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:02:57 - INFO: Sampling 16 new images....\n",
      "05:02:57 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 8, 7, 1, 1, 7, 6, 1, 4, 7, 7, 6, 7, 7, 2], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:20, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:04:21 - INFO: Sampling 16 new images....\n",
      "05:04:21 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(248.1439)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:20, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(274.1627)\n",
      "(tensor(248.1439), tensor(274.1627))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'F:\\Classes\\COMPSCI 682\\denoising-diffusion-pytorch-main\\ddpm\\models\\d_4_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pruned l1_unstructured models fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:41:26 - INFO: Sampling 16 new images....\n",
      "06:41:26 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5, 3, 0, 9, 0, 5, 3, 9, 0, 9, 0, 6, 3, 6], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:20, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:42:50 - INFO: Sampling 16 new images....\n",
      "06:42:50 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(274.0095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:19, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(276.0634)\n",
      "(tensor(274.0095), tensor(276.0634))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_l1_unstructured_10_base_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:47:13 - INFO: Sampling 16 new images....\n",
      "06:47:13 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 0, 0, 4, 8, 1, 9, 1, 5, 4, 7, 4, 2, 7, 5, 1], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:21, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:48:38 - INFO: Sampling 16 new images....\n",
      "06:48:38 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(284.6199)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:21, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(254.6614)\n",
      "(tensor(284.6199), tensor(254.6614))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_l1_unstructured_10_d_2_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:50:04 - INFO: Sampling 16 new images....\n",
      "06:50:04 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 3, 5, 9, 4, 6, 8, 8, 9, 9, 3, 0, 6, 3, 1], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:21, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:51:29 - INFO: Sampling 16 new images....\n",
      "06:51:29 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(263.8107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:24, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(288.1787)\n",
      "(tensor(263.8107), tensor(288.1787))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_l1_unstructured_10_d_4_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:52:58 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 0, 7, 9, 0, 4, 0, 7, 7, 8, 9, 0, 6, 7, 2, 4], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:52:58 - INFO: Sampling 16 new images....\n",
      "999it [01:26, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:54:29 - INFO: Sampling 16 new images....\n",
      "06:54:29 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(292.7821)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:24, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(284.0872)\n",
      "(tensor(292.7821), tensor(284.0872))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_l1_unstructured_30_base_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:55:58 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded models\n",
      "tensor([2, 9, 3, 2, 5, 0, 3, 1, 6, 6, 3, 0, 8, 0, 3, 4], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:55:58 - INFO: Sampling 16 new images....\n",
      "999it [01:24, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:57:26 - INFO: Sampling 16 new images....\n",
      "06:57:26 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(302.5300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:25, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(257.3767)\n",
      "(tensor(302.5300), tensor(257.3767))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_l1_unstructured_30_d_2_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:58:55 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 7, 3, 2, 5, 1, 5, 5, 9, 3, 4, 3, 7, 5, 5, 5], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:58:55 - INFO: Sampling 16 new images....\n",
      "999it [01:22, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:00:21 - INFO: Sampling 16 new images....\n",
      "07:00:21 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(204.8231)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:22, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(207.1623)\n",
      "(tensor(204.8231), tensor(207.1623))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_l1_unstructured_30_d_4_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pruned random models fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:01:48 - INFO: Sampling 16 new images....\n",
      "07:01:48 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 2, 7, 6, 6, 5, 4, 4, 7, 5, 3, 9, 3, 2, 9], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:22, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:03:15 - INFO: Sampling 16 new images....\n",
      "07:03:15 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(410.1934)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:22, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(224.0613)\n",
      "(tensor(410.1934), tensor(224.0613))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_random_10_base_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:04:41 - INFO: Sampling 16 new images....\n",
      "07:04:41 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 4, 7, 2, 8, 3, 1, 0, 2, 8, 6, 4, 4, 1, 9], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:23, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:06:09 - INFO: Sampling 16 new images....\n",
      "07:06:09 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(367.8468)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:24, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(360.7809)\n",
      "(tensor(367.8468), tensor(360.7809))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_random_10_d_2_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:07:37 - INFO: Sampling 16 new images....\n",
      "07:07:37 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 5, 4, 9, 6, 9, 0, 0, 5, 1, 9, 0, 9, 6, 3], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:22, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:09:03 - INFO: Sampling 16 new images....\n",
      "07:09:03 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(356.1158)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:22, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(358.8737)\n",
      "(tensor(356.1158), tensor(358.8737))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_random_10_d_4_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:10:29 - INFO: Sampling 16 new images....\n",
      "07:10:29 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 2, 4, 9, 2, 2, 0, 2, 9, 5, 8, 9, 9, 5, 9], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:19, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:11:52 - INFO: Sampling 16 new images....\n",
      "07:11:52 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(474.7346)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:21, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(493.6962)\n",
      "(tensor(474.7346), tensor(493.6962))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_random_30_base_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:13:17 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 3, 4, 8, 0, 3, 6, 6, 4, 4, 0, 4, 1, 7, 3, 3], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:13:17 - INFO: Sampling 16 new images....\n",
      "999it [01:25, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:14:46 - INFO: Sampling 16 new images....\n",
      "07:14:46 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(436.1765)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:24, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(478.7686)\n",
      "(tensor(436.1765), tensor(478.7686))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_random_30_d_2_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:16:15 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAAAAAAAAAAA\n",
      "loaded models\n",
      "tensor([2, 6, 0, 2, 3, 1, 5, 0, 8, 1, 4, 9, 1, 2, 2, 2], device='cuda:0') 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:16:15 - INFO: Sampling 16 new images....\n",
      "999it [01:24, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:17:44 - INFO: Sampling 16 new images....\n",
      "07:17:44 - INFO: Sampling 16 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional fid: tensor(462.5279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:23, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional ema fid: tensor(439.1877)\n",
      "(tensor(462.5279), tensor(439.1877))\n"
     ]
    }
   ],
   "source": [
    "model_path = r'models\\p_random_30_d_4_mnist_ddpm_conditional_ema'\n",
    "results = get_fid_score(model_path, dataloader, ('pruned_49_ckpt.pt', 'pruned_49_ema_ckpt.pt'))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDPM + CFG, Prune linear and conv2d globally 10%, Depthwise Convolutional Layers, 2 Groups\n",
    "DDPM + CFG + EMA, Prune linear and conv2d globally 30%, Depthwise Convolutional Layers, 2 Groups\n",
    "DDPM + CFG, Prune linear and conv2d globally 10%, Depthwise Convolutional Layers, 4 Groups\n",
    "DDPM + CFG + EMA,Prune linear and conv2d globally 30%, Depthwise Convolutional Layers, 4 Groups\n",
    "\n",
    "\n",
    "\n",
    "DDPM + CFG, Prune linear and conv2d globally 10%, Depthwise Convolutional Layers, 2 Groups\n",
    "DDPM + CFG + EMA, Prune linear and conv2d globally 30%, Depthwise Convolutional Layers, 2 Groups\n",
    "DDPM + CFG, Prune linear and conv2d globally 10%, Depthwise Convolutional Layers, 4 Groups\n",
    "DDPM + CFG + EMA,Prune linear and conv2d globally 30%, Depthwise Convolutional Layers, 4 Groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci682",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
