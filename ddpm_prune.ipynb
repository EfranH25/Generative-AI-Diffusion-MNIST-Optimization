{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook used to run & test prune diffusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/Users/Efran/anaconda3/envs/compsci682/lib'), WindowsPath('C')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('module'), WindowsPath('/matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 8.9.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n",
      "cant import bitsandbytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#? resources\n",
    "#? vid 1: https://www.youtube.com/watch?v=HoKDTa5jHvg&t=177s\n",
    "# explains how ddpm works\n",
    "#? vid2: https://www.youtube.com/watch?v=TBCRlnwJtZU\n",
    "# goes over implementation to ddpm\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from helper_utils import *\n",
    "\n",
    "from modules import UNet, UNet_conditional, EMA\n",
    "import logging \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# library for quantization\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "    print('imported bitsandbytes')\n",
    "    \n",
    "except:\n",
    "    print('cant import bitsandbytes')\n",
    "    bnb = None\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\", USE_GPU = True):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size #resoultion of image #: side note from video --> for higher resolutions, training seperate upsamplers instead of training on bigger resolution images\n",
    "        self.device = device\n",
    "        \n",
    "        if USE_GPU and torch.cuda.is_available():\n",
    "            print(\"CUDAAAAAAAAAAA\")\n",
    "            self.use_cuda = torch.device('cuda')\n",
    "        else:\n",
    "            self.use_cuda = torch.device('cpu')\n",
    "        \n",
    "        #? right now using simple beta schedule --> open AI using cosine scheduler        \n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "        \n",
    "        #! try implementing cosine scheduler\n",
    "        \n",
    "    def prepare_noise_schedule(self):\n",
    "        #? Creates a one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "    \n",
    "    def noise_images(self, x, t):\n",
    "        \"\"\"Adds noise to image. You can iteratively add noise to image but vid 1 showed \n",
    "        a simplification that adds noise in 1 step. Which is this implementation\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "            t (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: returns image with noise added on\n",
    "        \"\"\"\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        E = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * E, E\n",
    "    \n",
    "    def sample_timesteps(self, n):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        #? needed for algorithm for training\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "    \n",
    "\n",
    "    def sample(self, model, n, labels, channels=3, cfg_scale=3):\n",
    "        \"\"\"implements algorithm 2 from the ddpm paper in vid 1\n",
    "\n",
    "        Args:\n",
    "            model (_type_): _description_\n",
    "            n (int): number of images we want to sample \n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        #? see here for why we set model.eval() https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n",
    "        #? essentially disables some some parts of torch for specific steps\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            #? create initial images by sampling over normal dist (step 1)\n",
    "            x = torch.randn((n, channels, self.img_size, self.img_size)).to(self.device)\n",
    "            \n",
    "            #? step 2, 3, 4\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device) #? tensor of timestep\n",
    "                predicted_noise = model(x, t, labels) #? feed that into model w/ current images\n",
    "                \n",
    "                #? noise\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = model(x, t, None)\n",
    "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                \n",
    "                #? only want noise for timestemps greater than 1. done so b/c in last iteration, would make final outcome worse due to adding noise to finalized pixels\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                    \n",
    "                #? alter image by removed a little bit of noise\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        \n",
    "        #? switch back to train    \n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2 #? brings back value to 0-1 range \n",
    "        x = (x * 255).type(torch.uint8) #? bring back values to pixel range for viewing image\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "name = 'q_linear8_mnist_ddpm_conditional_ema'\n",
    "\n",
    "model_path = f'F:\\Classes\\COMPSCI 682\\denoising-diffusion-pytorch-main\\ddpm\\models\\{name}'\n",
    "\n",
    "\n",
    "def check_prune(model):\n",
    "  print(dict(model.named_buffers()).keys())\n",
    "  print(prune.is_pruned(model))\n",
    "  for name, module in model.named_modules():\n",
    "      if prune.is_pruned(module) == True:\n",
    "        print(prune.is_pruned(module))\n",
    "          \n",
    "  total_elements = 0\n",
    "  total = 0\n",
    "  for named_m, module in model.named_modules():\n",
    "    # print(named_m)\n",
    "    # if named_m in u_middle_layers:\n",
    "      # print(named_m)\n",
    "    for named_p, p in module.named_parameters():\n",
    "      #print(f\"{named_m}.{named_p}: {p.numel()}\")\n",
    "      total_elements += p.numel()\n",
    "      total += torch.count_nonzero(p.data)\n",
    "\n",
    "  print(total_elements)\n",
    "  print(total)\n",
    "\n",
    "def prune_model(model, prune_method, proportion):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            #print(name, module)\n",
    "            prune_method(module, name='weight', amount=proportion)\n",
    "            prune.remove(module, 'weight')\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            #print(name, module)\n",
    "            prune_method(module, name='weight', amount=proportion)\n",
    "            prune.remove(module, 'weight')\n",
    "            prune_method(module, name='bias', amount=proportion)\n",
    "            prune.remove(module, 'bias')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/Users/Efran/anaconda3/envs/compsci682/lib'), WindowsPath('C')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('module'), WindowsPath('/matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 8.9.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\Classes\\COMPSCI 682\\denoising-diffusion-pytorch-main\\ddpm\\ddpm_prune.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Classes/COMPSCI%20682/denoising-diffusion-pytorch-main/ddpm/ddpm_prune.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m proportion \u001b[39min\u001b[39;00m proportion_list:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Classes/COMPSCI%20682/denoising-diffusion-pytorch-main/ddpm/ddpm_prune.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m method_list:\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Classes/COMPSCI%20682/denoising-diffusion-pytorch-main/ddpm/ddpm_prune.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m#? load models\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Classes/COMPSCI%20682/denoising-diffusion-pytorch-main/ddpm/ddpm_prune.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         loaded_unet_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(model_path, \u001b[39m'\u001b[39;49m\u001b[39m49_ckpt.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Classes/COMPSCI%20682/denoising-diffusion-pytorch-main/ddpm/ddpm_prune.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m#loaded_unet_model.eval()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Classes/COMPSCI%20682/denoising-diffusion-pytorch-main/ddpm/ddpm_prune.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         loaded_ema_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39m49_ema_ckpt.pt\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\torch\\serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1014\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[0;32m   1015\u001b[0m                      map_location,\n\u001b[0;32m   1016\u001b[0m                      pickle_module,\n\u001b[0;32m   1017\u001b[0m                      overall_storage\u001b[39m=\u001b[39moverall_storage,\n\u001b[0;32m   1018\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[0;32m   1020\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmmap can only be used with files saved with \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1021\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1022\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\torch\\serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1420\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1421\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1422\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1424\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1425\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1426\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[0;32m   1427\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\torch\\serialization.py:1415\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m mod_name \u001b[39m=\u001b[39m load_module_mapping\u001b[39m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1415\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfind_class(mod_name, name)\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     matmul_4bit\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\research\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     switchback_bnb,\n\u001b[0;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[0;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\research\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\research\\nn\\modules.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalOptimManager\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[0;32m     11\u001b[0m T \u001b[39m=\u001b[39m TypeVar(\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, bound\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch.nn.Module\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\optim\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madagrad\u001b[39;00m \u001b[39mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madam\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "File \u001b[1;32mc:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\cextension.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mgenerate_instructions()\n\u001b[0;32m     19\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[39m    python -m bitsandbytes\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[39m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[39m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[39m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[39m'''\u001b[39m)\n\u001b[0;32m     28\u001b[0m lib\u001b[39m.\u001b[39mcadam32bit_grad_fp32 \u001b[39m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n\u001b[0;32m     29\u001b[0m lib\u001b[39m.\u001b[39mget_context\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mc_void_p\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "proportion_list = [.1, .3]\n",
    "method_list = ['random', \"l1_unstructured\"]\n",
    "prune_methods = {\n",
    "    \"random\": prune.random_unstructured,\n",
    "    \"l1_unstructured\": prune.l1_unstructured}\n",
    "\n",
    "\n",
    "for proportion in proportion_list:\n",
    "    for method in method_list:\n",
    "        #? load models\n",
    "        loaded_unet_model = torch.load(os.path.join(model_path, '49_ckpt.pt'))\n",
    "        #loaded_unet_model.eval()\n",
    "        loaded_ema_model = torch.load(os.path.join(model_path, '49_ema_ckpt.pt'))\n",
    "        #loaded_ema_model.eval()\n",
    "        \n",
    "        check_prune(loaded_unet_model)\n",
    "        check_prune(loaded_ema_model)\n",
    "        print('********** BEFORE PRUNE')\n",
    "        \n",
    "        prune_method = prune_methods[method]\n",
    "        print(proportion, method, prune_method)\n",
    "        pruned_unet = prune_model(loaded_unet_model, prune_method, proportion)\n",
    "        pruned_ema = prune_model(loaded_ema_model, prune_method, proportion)\n",
    "\n",
    "        check_prune(pruned_unet)\n",
    "        check_prune(pruned_ema)\n",
    "        print('********** AFTER PRUNE')\n",
    "        \n",
    "        prune_model_path = f'models\\p_{method}_{int(proportion*100)}_{name}'\n",
    "        if os.path.exists(prune_model_path) == False:    \n",
    "            os.makedirs(prune_model_path)\n",
    "        \n",
    "        torch.save(pruned_unet, os.path.join(prune_model_path, f\"pruned_49_ckpt.pt\"))\n",
    "        torch.save(pruned_ema, os.path.join(prune_model_path, f\"pruned_49_ema_ckpt.pt\"))\n",
    "        \n",
    "        print('--------------------------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci682",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
