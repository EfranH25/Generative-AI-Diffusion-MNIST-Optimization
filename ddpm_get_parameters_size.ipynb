{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook used to get parameter count and model size from diffusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch._C' from 'c:\\\\Users\\\\Efran\\\\anaconda3\\\\envs\\\\compsci682\\\\lib\\\\site-packages\\\\torch\\\\_C.cp310-win_amd64.pyd'>\n",
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('C'), WindowsPath('/Users/Efran/anaconda3/envs/compsci682/lib')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 8.9.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n",
      "cant import bitsandbytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: C:\\Users\\Efran\\anaconda3\\envs\\compsci682 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('C'), WindowsPath('/Users/Efran/anaconda3/envs/compsci682/lib')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 8.9.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\Efran\\anaconda3\\envs\\compsci682\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n",
      "cant import bitsandbytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#? resources\n",
    "#? vid 1: https://www.youtube.com/watch?v=HoKDTa5jHvg&t=177s\n",
    "# explains how ddpm works\n",
    "#? vid2: https://www.youtube.com/watch?v=TBCRlnwJtZU\n",
    "# goes over implementation to ddpm\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from helper_utils import *\n",
    "\n",
    "from modules import UNet, UNet_conditional, EMA\n",
    "import logging \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# library for quantization\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "    print('imported bitsandbytes')\n",
    "    \n",
    "except:\n",
    "    print('cant import bitsandbytes')\n",
    "    bnb = None\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\", USE_GPU = True):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size #resoultion of image #: side note from video --> for higher resolutions, training seperate upsamplers instead of training on bigger resolution images\n",
    "        self.device = device\n",
    "        \n",
    "        if USE_GPU and torch.cuda.is_available():\n",
    "            print(\"CUDAAAAAAAAAAA\")\n",
    "            self.use_cuda = torch.device('cuda')\n",
    "        else:\n",
    "            self.use_cuda = torch.device('cpu')\n",
    "        \n",
    "        #? right now using simple beta schedule --> open AI using cosine scheduler        \n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "        \n",
    "        #! try implementing cosine scheduler\n",
    "        \n",
    "    def prepare_noise_schedule(self):\n",
    "        #? Creates a one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "    \n",
    "    def noise_images(self, x, t):\n",
    "        \"\"\"Adds noise to image. You can iteratively add noise to image but vid 1 showed \n",
    "        a simplification that adds noise in 1 step. Which is this implementation\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "            t (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: returns image with noise added on\n",
    "        \"\"\"\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        E = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * E, E\n",
    "    \n",
    "    def sample_timesteps(self, n):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        #? needed for algorithm for training\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "    \n",
    "\n",
    "    def sample(self, model, n, labels, channels=3, cfg_scale=3):\n",
    "        \"\"\"implements algorithm 2 from the ddpm paper in vid 1\n",
    "\n",
    "        Args:\n",
    "            model (_type_): _description_\n",
    "            n (int): number of images we want to sample \n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        #? see here for why we set model.eval() https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n",
    "        #? essentially disables some some parts of torch for specific steps\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            #? create initial images by sampling over normal dist (step 1)\n",
    "            x = torch.randn((n, channels, self.img_size, self.img_size)).to(self.device)\n",
    "            \n",
    "            #? step 2, 3, 4\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device) #? tensor of timestep\n",
    "                predicted_noise = model(x, t, labels) #? feed that into model w/ current images\n",
    "                \n",
    "                #? noise\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = model(x, t, None)\n",
    "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                \n",
    "                #? only want noise for timestemps greater than 1. done so b/c in last iteration, would make final outcome worse due to adding noise to finalized pixels\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                    \n",
    "                #? alter image by removed a little bit of noise\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        \n",
    "        #? switch back to train    \n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2 #? brings back value to 0-1 range \n",
    "        x = (x * 255).type(torch.uint8) #? bring back values to pixel range for viewing image\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Params Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_elems_params(model):\n",
    "    total_params = 0\n",
    "    total_nonzero_params = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()\n",
    "        total_nonzero_params += torch.count_nonzero(param)\n",
    "    \n",
    "    return total_params, total_nonzero_params.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\base_mnist_ddpm_conditional_ema\\49_ckpt.pt 17868145 17868145\n",
      "models\\base_mnist_ddpm_conditional_ema\\49_ema_ckpt.pt 17868145 17868145\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "models\\d_2_mnist_ddpm_conditional_ema\\49_ckpt.pt 14029681 14029681\n",
      "models\\d_2_mnist_ddpm_conditional_ema\\49_ema_ckpt.pt 14029681 14029681\n",
      "----------------------------------------------------------\n",
      "models\\d_4_mnist_ddpm_conditional_ema\\49_ckpt.pt 12110449 12110449\n",
      "models\\d_4_mnist_ddpm_conditional_ema\\49_ema_ckpt.pt 12110449 12110449\n",
      "----------------------------------------------------------\n",
      "models\\p_l1_unstructured_10_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 17868145 16122904\n",
      "models\\p_l1_unstructured_10_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 17868145 16122904\n",
      "----------------------------------------------------------\n",
      "models\\p_l1_unstructured_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 14029681 12668288\n",
      "models\\p_l1_unstructured_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 14029681 12668288\n",
      "----------------------------------------------------------\n",
      "models\\p_l1_unstructured_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 12110449 10940980\n",
      "models\\p_l1_unstructured_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 12110449 10940980\n",
      "----------------------------------------------------------\n",
      "models\\p_l1_unstructured_30_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 17868145 12632423\n",
      "models\\p_l1_unstructured_30_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 17868145 12632423\n",
      "----------------------------------------------------------\n",
      "models\\p_l1_unstructured_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 14029681 9945499\n",
      "models\\p_l1_unstructured_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 14029681 9945499\n",
      "----------------------------------------------------------\n",
      "models\\p_l1_unstructured_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 12110449 8602035\n",
      "models\\p_l1_unstructured_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 12110449 8602035\n",
      "----------------------------------------------------------\n",
      "models\\p_random_10_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 17868145 16122904\n",
      "models\\p_random_10_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 17868145 16122904\n",
      "----------------------------------------------------------\n",
      "models\\p_random_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 14029681 12668288\n",
      "models\\p_random_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 14029681 12668288\n",
      "----------------------------------------------------------\n",
      "models\\p_random_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 12110449 10940980\n",
      "models\\p_random_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 12110449 10940980\n",
      "----------------------------------------------------------\n",
      "models\\p_random_30_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 17868145 12632423\n",
      "models\\p_random_30_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 17868145 12632423\n",
      "----------------------------------------------------------\n",
      "models\\p_random_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 14029681 9945499\n",
      "models\\p_random_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 14029681 9945499\n",
      "----------------------------------------------------------\n",
      "models\\p_random_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt 12110449 8602035\n",
      "models\\p_random_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt 12110449 8602035\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models'\n",
    "model_list = os.listdir(model_path)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for model_type in model_list:\n",
    "    saved_models = os.listdir(os.path.join(model_path, model_type))\n",
    "    \n",
    "    if '49_ckpt.pt' in saved_models and '49_ema_ckpt.pt' in saved_models:\n",
    "        cfg = os.path.join(model_path, model_type, '49_ckpt.pt')\n",
    "        cfg_model = torch.load(cfg)\n",
    "        total_params, total_nonzero_params = model_elems_params(cfg_model)\n",
    "        print(os.path.join(model_path, model_type, '49_ckpt.pt'), total_params, total_nonzero_params)\n",
    "        \n",
    "        ema = os.path.join(model_path, model_type, '49_ema_ckpt.pt')\n",
    "        ema_model = torch.load(ema)\n",
    "        total_params, total_nonzero_params = model_elems_params(ema_model)\n",
    "        print(os.path.join(model_path, model_type, '49_ema_ckpt.pt'), total_params, total_nonzero_params)\n",
    "        #count += 2\n",
    "        \n",
    "        \n",
    "    elif 'pruned_49_ckpt.pt' in saved_models and 'pruned_49_ema_ckpt.pt' in saved_models:\n",
    "        cfg = os.path.join(model_path, model_type, 'pruned_49_ckpt.pt')\n",
    "        cfg_model = torch.load(cfg)\n",
    "        total_params, total_nonzero_params = model_elems_params(cfg_model)\n",
    "        print(os.path.join(model_path, model_type, 'pruned_49_ckpt.pt'), total_params, total_nonzero_params)\n",
    "        \n",
    "        ema = os.path.join(model_path, model_type, 'pruned_49_ema_ckpt.pt')\n",
    "        ema_model = torch.load(ema)\n",
    "        total_params, total_nonzero_params = model_elems_params(ema_model)\n",
    "        print(os.path.join(model_path, model_type, 'pruned_49_ema_ckpt.pt'), total_params, total_nonzero_params)\n",
    "        #count += 2\n",
    "    print('----------------------------------------------------------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models'\n",
    "new_model_path = 'model_state_dict'\n",
    "model_list = os.listdir(model_path)\n",
    "\n",
    "for model_type in model_list:\n",
    "    saved_models = os.listdir(os.path.join(model_path, model_type))\n",
    "    \n",
    "    if '49_ckpt.pt' in saved_models and '49_ema_ckpt.pt' in saved_models:\n",
    "        cfg = os.path.join(model_path, model_type, '49_ckpt.pt')\n",
    "        cfg_model = torch.load(cfg)\n",
    "\n",
    "        \n",
    "        ema = os.path.join(model_path, model_type, '49_ema_ckpt.pt')\n",
    "        ema_model = torch.load(ema)\n",
    "        \n",
    "        save_loc = os.path.join(new_model_path, model_type)\n",
    "        if os.path.exists(save_loc) == False:\n",
    "            os.makedirs(save_loc)\n",
    "        \n",
    "        torch.save(cfg_model.state_dict(), os.path.join(save_loc, '49_ckpt.pt'))\n",
    "        torch.save(ema_model.state_dict(), os.path.join(save_loc, '49_ema_ckpt.pt'))\n",
    "        \n",
    "    elif 'pruned_49_ckpt.pt' in saved_models and 'pruned_49_ema_ckpt.pt' in saved_models:\n",
    "        cfg = os.path.join(model_path, model_type, 'pruned_49_ckpt.pt')\n",
    "        cfg_model = torch.load(cfg)\n",
    "        \n",
    "        \n",
    "        ema = os.path.join(model_path, model_type, 'pruned_49_ema_ckpt.pt')\n",
    "        ema_model = torch.load(ema)\n",
    "        \n",
    "        save_loc = os.path.join(new_model_path, model_type)\n",
    "        if os.path.exists(save_loc) == False:\n",
    "            os.makedirs(save_loc)\n",
    "        torch.save(cfg_model.state_dict(), os.path.join(save_loc, 'pruned_49_ckpt.pt'))\n",
    "        torch.save(ema_model.state_dict(), os.path.join(save_loc, 'pruned_49_ema_ckpt.pt'))\n",
    "    \n",
    "    print('----------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip -qfc '49_ckpt.pt' > '49_ckpt.pt.gz'\n",
    "gzip -qfc '49_ema_ckpt.pt' > '49_ema_ckpt.pt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip -qfc 'pruned_49_ckpt.pt' > 'pruned_49_ckpt.pt.gz'\n",
    "gzip -qfc 'pruned_49_ema_ckpt.pt' > 'pruned_49_ema_ckpt.pt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_state_dict\\base_mnist_ddpm_conditional_ema\\49_ckpt.pt.gz 66538096\n",
      "model_state_dict\\base_mnist_ddpm_conditional_ema\\49_ema_ckpt.pt.gz 66538147\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\d_2_mnist_ddpm_conditional_ema\\49_ckpt.pt.gz 52203120\n",
      "model_state_dict\\d_2_mnist_ddpm_conditional_ema\\49_ema_ckpt.pt.gz 52204450\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\d_4_mnist_ddpm_conditional_ema\\49_ckpt.pt.gz 45030932\n",
      "model_state_dict\\d_4_mnist_ddpm_conditional_ema\\49_ema_ckpt.pt.gz 45031920\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_l1_unstructured_10_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 62448687\n",
      "model_state_dict\\p_l1_unstructured_10_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 62448829\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_l1_unstructured_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 49014554\n",
      "model_state_dict\\p_l1_unstructured_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 49015306\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_l1_unstructured_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 42312936\n",
      "model_state_dict\\p_l1_unstructured_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 42312880\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_l1_unstructured_30_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 52029548\n",
      "model_state_dict\\p_l1_unstructured_30_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 52030922\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_l1_unstructured_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 40941790\n",
      "model_state_dict\\p_l1_unstructured_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 40944802\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_l1_unstructured_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 35396803\n",
      "model_state_dict\\p_l1_unstructured_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 35396361\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_random_10_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 62981643\n",
      "model_state_dict\\p_random_10_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 62982310\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_random_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 49453214\n",
      "model_state_dict\\p_random_10_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 49454160\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_random_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 42671181\n",
      "model_state_dict\\p_random_10_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 42672362\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_random_30_base_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 53349095\n",
      "model_state_dict\\p_random_30_base_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 53349687\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_random_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 41978895\n",
      "model_state_dict\\p_random_30_d_2_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 41981589\n",
      "----------------------------------------------------------\n",
      "model_state_dict\\p_random_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ckpt.pt.gz 36269068\n",
      "model_state_dict\\p_random_30_d_4_mnist_ddpm_conditional_ema\\pruned_49_ema_ckpt.pt.gz 36271677\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_model_path = 'model_state_dict'\n",
    "model_list = os.listdir(new_model_path)\n",
    "\n",
    "for model_type in model_list:\n",
    "    zipped_models = os.listdir(os.path.join(new_model_path, model_type))\n",
    "    #print(zipped_models)\n",
    "    if 'pruned_49_ckpt.pt.gz' in zipped_models and 'pruned_49_ema_ckpt.pt.gz' in zipped_models:\n",
    "        cfg = os.path.join(new_model_path, model_type, 'pruned_49_ckpt.pt.gz')\n",
    "        ema = os.path.join(new_model_path, model_type, 'pruned_49_ema_ckpt.pt.gz')\n",
    "        \n",
    "        print(cfg, os.path.getsize(cfg))\n",
    "        print(ema, os.path.getsize(ema))\n",
    "        \n",
    "    if '49_ckpt.pt.gz' in zipped_models and '49_ema_ckpt.pt.gz' in zipped_models:\n",
    "        cfg = os.path.join(new_model_path, model_type, '49_ckpt.pt.gz')\n",
    "        ema = os.path.join(new_model_path, model_type, '49_ema_ckpt.pt.gz')\n",
    "        print(cfg, os.path.getsize(cfg))\n",
    "        print(ema, os.path.getsize(ema))\n",
    "        \n",
    "    print('----------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci682",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
